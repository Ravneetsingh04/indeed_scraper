name: Scrape ZipRecruiter Jobs Daily

on:
  schedule:
    - cron: '0 10 * * *'  # Runs every day at 10:00 AM UTC
  workflow_dispatch:

permissions:
  contents: write  # Allows workflow to push CSV back to repo

jobs:
  scrape_jobs:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install scrapy requests pandas

      - name: Run ZipRecruiter Spider (First Page Only)
        working-directory: indeed_scraper
        run: |
          echo "üöÄ Running ZipRecruiter spider (no API)..."
          scrapy crawl ziprecruiter -O $GITHUB_WORKSPACE/zip_jobs.csv

          echo "‚úÖ Scraping completed."
          ls -lh $GITHUB_WORKSPACE/zip_jobs.csv
          head -n 10 $GITHUB_WORKSPACE/zip_jobs.csv || echo "‚ùó CSV is empty!"

      - name: Commit and push results
        run: |
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          git add zip_jobs.csv || echo "No file to add"
          git commit -m "Update ZipRecruiter job data" || echo "No changes to commit"
          git push
